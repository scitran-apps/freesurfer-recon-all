#! /bin/bash
#
# Run freesurfer-recon-all Gear
# Built to flywheel-v0 spec.
#
# https://surfer.nmr.mgh.harvard.edu/fswiki/ReconAllOutputFiles

GEAR=freesurfer-recon-all-dev
REPO=scitran
CONTAINER="[${REPO}/$GEAR]"

echo -e "$CONTAINER  Initiated"
set -e
###############################################################################
# Utilities

# Remove the spaces in directory and filenames recursively
despacer () {
  find "$1" -depth -name "* *" -execdir rename 's/ /_/g' "{}" \;
}

###############################################################################
# Configure Freesurfer and MCR ENV

export OS=Linux
export FS_OVERRIDE=0
export FIX_VERTEX_AREA=
export FSF_OUTPUT_FORMAT=nii.gz
export MNI_DIR=/opt/freesurfer/mni
export LOCAL_DIR=/opt/freesurfer/local
export FREESURFER_HOME=/opt/freesurfer
export FSFAST_HOME=/opt/freesurfer/fsfast
export MINC_BIN_DIR=/opt/freesurfer/mni/bin
export MINC_LIB_DIR=/opt/freesurfer/mni/lib
export MNI_DATAPATH=/opt/freesurfer/mni/data
export FMRI_ANALYSIS_DIR=/opt/freesurfer/fsfast
export PERL5LIB=/opt/freesurfer/mni/lib/perl5/5.8.5
export MNI_PERL5LIB=/opt/freesurfer/mni/lib/perl5/5.8.5
export XAPPLRESDIR=/opt/freesurfer/MCRv84/X11/app-defaults
export PATH=/opt/freesurfer/bin:/opt/freesurfer/fsfast/bin:/opt/freesurfer/tktools:/opt/freesurfer/mni/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin

# Source FreeSurferEnv.sh then set subjects_dir
/bin/bash -c 'source $FREESURFER_HOME/FreeSurferEnv.sh &>/dev/null'

export SUBJECTS_DIR=/opt/freesurfer/subjects

###############################################################################
# Configure paths

FLYWHEEL_BASE=/flywheel/v0
OUTPUT_DIR=${FLYWHEEL_BASE}/output
INPUT_DIR=${FLYWHEEL_BASE}/input
ANAT_DIR=${INPUT_DIR}/anatomical
ANAT_DIR_2=${INPUT_DIR}/t1w_anatomical_2
ANAT_DIR_3=${INPUT_DIR}/t1w_anatomical_3
ANAT_DIR_4=${INPUT_DIR}/t1w_anatomical_4
ANAT_DIR_5=${INPUT_DIR}/t1w_anatomical_5
T2_DIR=${INPUT_DIR}/t2w_anatomical
LICENSE_FILE=${FREESURFER_HOME}/.license
TEMPLATES=${FLYWHEEL_BASE}/templates
MORI_DIR=${FLYWHEEL_BASE}/templates/MNI_JHU_tracts_ROIs
FS_DIR=${OUTPUT_DIR}/fs
ROIs_DIR=${OUTPUT_DIR}/fs/ROIs

###############################################################################
# Parse Configuration and Set Options

CONFIG_FILE=${FLYWHEEL_BASE}/config.json
MANIFEST_FILE=${FLYWHEEL_BASE}/manifest.json

if [[ ! -f ${CONFIG_FILE} ]]; then
  CONFIG_FILE=${MANIFEST_FILE}
fi

# If the license file is empty then create from config inputs
if [[ ! -f ${LICENSE_FILE} ]]; then
  LICENSE=$(${FLYWHEEL_BASE}/parse_config.py --json_file=${CONFIG_FILE} -l)
  if [[ -z $LICENSE ]]; then
    echo "NO LICENSE INFORMATION FOUND! Exiting(1)"
    exit 1
  fi
  echo -e ${LICENSE} > ${LICENSE_FILE}
fi

if [[ -z $1 ]] ;
then
SUBJECT_ID=$(echo `${FLYWHEEL_BASE}/parse_config.py --json_file=${CONFIG_FILE} -i` | sed 's/ /_/g');
else
SUBJECT_ID=$1
fi
echo $1
echo $SUBJECT_ID
RECON_ALL_OPTS=`${FLYWHEEL_BASE}/parse_config.py --json_file=${CONFIG_FILE} -o`
CONVERT_SURFACES=`${FLYWHEEL_BASE}/parse_config.py --json_file=${CONFIG_FILE} -s`
CONVERT_VOLUMES=`${FLYWHEEL_BASE}/parse_config.py --json_file=${CONFIG_FILE} -n`
ASEG_CSV=`${FLYWHEEL_BASE}/parse_config.py --json_file=${CONFIG_FILE} -a`
HIPPOCAMPUS=`${FLYWHEEL_BASE}/parse_config.py --json_file=${CONFIG_FILE} -c`
BRAINSTEM=`${FLYWHEEL_BASE}/parse_config.py --json_file=${CONFIG_FILE} -b`
THALAMUS=`${FLYWHEEL_BASE}/parse_config.py --json_file=${CONFIG_FILE} -t`
HCP=`${FLYWHEEL_BASE}/parse_config.py --json_file=${CONFIG_FILE} -g`
NEUROPYTHY=`${FLYWHEEL_BASE}/parse_config.py --json_file=${CONFIG_FILE} -p`
REGISTER_SURFACES=`${FLYWHEEL_BASE}/parse_config.py --json_file=${CONFIG_FILE} -r`
CEREBELLUM=`${FLYWHEEL_BASE}/parse_config.py --json_file=${CONFIG_FILE} -e`
MORI=`${FLYWHEEL_BASE}/parse_config.py --json_file=${CONFIG_FILE} -m` 
APARC2009=`${FLYWHEEL_BASE}/parse_config.py --json_file=${CONFIG_FILE} -aparc2009`
# Make and link the subject's directory
WORK_DIR=/"${SUBJECT_ID}"
ln -sfn ${SUBJECTS_DIR}/"${SUBJECT_ID}" ${WORK_DIR}


###############################################################################
# Check for anatomical NIfTI or DICOM archive

# Despace filenames
despacer "${ANAT_DIR}"

# NIfTI input file
ANATOMICAL=$(find ${ANAT_DIR}/* -name "*.nii*")

# DICOM archive
if [[ -z "${ANATOMICAL}" ]]; then
  ANATOMICAL=$(find $INPUT_DIR/* -not -path '*/\.*' -type f | head -1)

  # Handle Zip archive or uncompressed volume
  if [[ "${ANATOMICAL}" == *.zip ]]; then
    echo "$CONTAINER  Unzipping $ANATOMICAL"
    DICOM_DIR="${ANAT_DIR}"/dicoms
    mkdir ${DICOM_DIR}
    unzip -q "${ANATOMICAL}" -d ${DICOM_DIR}

    # Get the 'despaced' path to the first dicom file for input to recon-all
    despacer "${DICOM_DIR}"
    ANATOMICAL=$(find ${DICOM_DIR}/* -not -path '*/\.*' -type f | head -1)
  fi

  # Final check for anatomical file
  if [[ -z "${ANATOMICAL}" ]]; then
    echo "$CONTAINER  Anatomical input could not be found in $ANAT_DIR! Exiting (1)"
    ls -lRa ${ANAT_DIR}
    exit 1
  fi
fi


###############################################################################
# Check for anatomical NIfTI or DICOM archive


  # Despace filenames
  despacer "${ANAT_DIR}"

  # NIfTI input file
  ANATOMICAL=$(find ${ANAT_DIR}/* -name "t1.nii.gz")

 # DICOM archive
 if [[ -z "${ANATOMICAL}" ]]; then
    ANATOMICAL=$(find $INPUT_DIR/* -not -path '*/\.*' -type f | head -1)

    # Handle Zip archive or uncompressed volume
    if [[ "${ANATOMICAL}" == *.zip ]]; then
      echo "$CONTAINER  Unzipping $ANATOMICAL"
      DICOM_DIR="${ANAT_DIR}"/dicoms
      mkdir ${DICOM_DIR}
      unzip -q "${ANATOMICAL}" -d ${DICOM_DIR}

      # Get the 'despaced' path to the first dicom file for input to recon-all
      despacer "${DICOM_DIR}"
      ANATOMICAL=$(find ${DICOM_DIR}/* -not -path '*/\.*' -type f | head -1)
    fi

    # Final check for anatomical file
    if [[ -z "${ANATOMICAL}" ]]; then
      echo "$CONTAINER  Anatomical input could not be found in $ANAT_DIR! Exiting (1)"
      ls -lRa ${ANAT_DIR}
      exit 1
    fi
fi
# Proccess additional anatomical inputs
ADD_INPUTS=''
ANAT_DIRS=$(echo -e $ANAT_DIR_2 $ANAT_DIR_3 $ANAT_DIR_4 $ANAT_DIR_5)
for ad in $ANAT_DIRS; do
  if [ -d ${ad} ]; then
    despacer ${ad}
    ANATOMICAL2=$(find ${ad}/* -name "*.nii*")
    if [[ -f "$ANATOMICAL2" ]]; then
      echo "Adding $ANATOMICAL2 to the processing stream..."
      ADD_INPUTS=$ADD_INPUTS' -i '"$ANATOMICAL2"
    fi
  fi
done

# T2 input file
if [[ -d ${T2_DIR} ]]; then
  despacer ${T2_DIR}
  T2_ANAT=$(find ${T2_DIR}/* -name "*.nii*")
  if [[ -f "$T2_ANAT" ]]; then
    ADD_INPUTS=$ADD_INPUTS' -T2 '"$T2_ANAT"' -T2pial '
  fi
fi


###############################################################################
# Run Freesurfer-Recon-all
if [[  ${RECON_ALL_OPTS} == "False" ]];then
  echo -e "recon all is false, skipping it"
  echo -e "checking if the old freesurfer-recon-all*.zip is there"
  FS_ARCHIVE=$(find ${OUTPUT_DIR}/* -name "freesurfer-recon-all*.zip")
  if [[ -f "$FS_ARCHIVE" ]]; then
      echo -e "unzipping existing ${FS_ARCHIVE}"
      unzip -oq "${FS_ARCHIVE}" -d "${OUTPUT_DIR}"
  else
      echo -e "$CONTAINER We cannot find existing .zip file"
      echo "$CONTAINER  GEAR FAILED... Exiting(1)"
      exit 1
  fi
  echo -e "linking SUBJECTS_DIR directory to freesurfer"
  ln -sfn ${OUTPUT_DIR}/${SUBJECT_ID} ${SUBJECTS_DIR}/"${SUBJECT_ID}"
  else 
# Run recon-all
    echo -e "Running recon all..."
    command=$(echo -e "time recon-all -i "${ANATOMICAL}" "${ADD_INPUTS}" -subjid "${SUBJECT_ID}" ${RECON_ALL_OPTS}")
    echo -e "${command}"
    eval $command
fi
if [[ $? != 0 ]]; then
  echo "$CONTAINER  recon-all failure! Exiting (1)"
  exit 1
fi

###############################################################################
# Optional Segmentations

MRI_DIR=${SUBJECTS_DIR}/"${SUBJECT_ID}"/mri

if [[ ! -d $FS_DIR ]]; then
  mkdir ${FS_DIR}
fi

if [[ ! -d $ROIs_DIR ]]; then
  mkdir ${ROIs_DIR}
fi

# Segmentation of Cerebellum 
if [[ ${CEREBELLUM} == "True" ]]; then
  echo -e "$CONTAINER starting segmentation of cerebellum"
  # Create binary mask of brainmask.mgz and MNI_152
  mri_convert ${MRI_DIR}/brainmask.mgz ${MRI_DIR}/brainmask.nii.gz
  mri_binarize --min 0.1 --i ${MRI_DIR}/brainmask.mgz --o ${MRI_DIR}/binbrainmask.nii.gz
  mri_binarize --min 0.1 --i ${TEMPLATES}/MNI_152.nii.gz --o ${MRI_DIR}/binMNI_152.nii.gz
  # calculate the transformation
  antsRegistrationSyN.sh -d 3 -o ${MRI_DIR}/ants								\
		-f ${MRI_DIR}/brainmask.nii.gz -m ${TEMPLATES}/MNI_152.nii.gz
  # apply both affine and nonlinear transofrmation
  antsApplyTransforms -d 3 														\
		-i ${TEMPLATES}/Buckner_CB.nii.gz									\
		-r ${MRI_DIR}/brainmask.nii.gz											\
		-n GenericLabel[Linear]													\
		-t ${MRI_DIR}/ants1Warp.nii.gz											\
		-t ${MRI_DIR}/ants0GenericAffine.mat									\
		-o ${MRI_DIR}/buckner2011_cerebellum.nii.gz
  # copy it to output dir
  mv ${MRI_DIR}/buckner2011_cerebellum.nii.gz \
			${OUTPUT_DIR}/buckner2011_cerebellum.nii.gz
fi
# transform MORI to native space
if [[ ${MORI} == "True" ]]; then
  echo -e "$CONTRAINER starting transform MORI"
  if [[ ${CEREBELLUM} != "True" ]]; then
	# Create binary mask of brainmask.mgz and MNI_152
    mri_convert  ${MRI_DIR}/brainmask.mgz ${MRI_DIR}/brainmask.nii.gz
    mri_binarize --min 0.1 --i ${MRI_DIR}/brainmask.mgz --o ${MRI_DIR}/binbrainmask.nii.gz
    mri_binarize --min 0.1 --i ${TEMPLATES}/MNI_152.nii.gz --o ${MRI_DIR}/binMNI_152.nii.gz
  # calculate the transformation
  antsRegistrationSyN.sh -d 3 -o ${MRI_DIR}/ants								\
		-f ${MRI_DIR}/brainmask.nii.gz -m ${TEMPLATES}/MNI_152.nii.gz
  fi
  for ROI in `ls ${MORI_DIR}/*`; do
    ROIname=$(basename -- "$ROI"); ROIname="${ROIname%.nii.gz}"  
    antsApplyTransforms -d 3 														\
		-i ${MORI_DIR}/${ROIname}.nii.gz									\
		-r ${MRI_DIR}/brainmask.nii.gz											\
		-n GenericLabel[Linear]																\
		-t ${MRI_DIR}/ants1Warp.nii.gz											\
		-t ${MRI_DIR}/ants0GenericAffine.mat									\
		-o ${MRI_DIR}/MORI_${ROIname}.nii.gz
    
    mri_binarize --min 0.1 --i ${MRI_DIR}/MORI_${ROIname}.nii.gz \
						--o ${ROIs_DIR}/${ROIname}.nii.gz
    rm ${MRI_DIR}/MORI_${ROIname}.nii.gz 
  done
fi
# transform HCP atlas to native space
if [[ ${HCP} == "True" ]]; then
  echo -e "$CONTRAINER starting transform HCP atlas to native space"
  if [[ ${CEREBELLUM} != "True" ]]; then
	# Create binary mask of brainmask.mgz and MNI_152
    mri_convert  ${MRI_DIR}/brainmask.mgz ${MRI_DIR}/brainmask.nii.gz
    mri_binarize --min 0.1 --i ${MRI_DIR}/brainmask.mgz --o ${MRI_DIR}/binbrainmask.nii.gz
    mri_binarize --min 0.1 --i ${TEMPLATES}/MNI_152.nii.gz --o ${MRI_DIR}/binMNI_152.nii.gz
    # calculate the transformation
    antsRegistrationSyN.sh -d 3 -o ${MRI_DIR}/ants								\
		-f ${MRI_DIR}/brainmask.nii.gz -m ${TEMPLATES}/MNI_152.nii.gz
  fi
  # apply both affine and nonlinear transofrmation
  antsApplyTransforms -d 3 														\
		-i ${TEMPLATES}/MNI_Glasser_HCP_v1.0.nii.gz								\
		-r ${MRI_DIR}/brainmask.nii.gz											\
		-n GenericLabel[Linear]													\
		-t ${MRI_DIR}/ants1Warp.nii.gz											\
		-t ${MRI_DIR}/ants0GenericAffine.mat									\
		-o ${MRI_DIR}/Glasser_HCP_v1.0.nii.gz
  # copy it to output dir
  mv ${MRI_DIR}/Glasser_HCP_v1.0.nii.gz          \
			${OUTPUT_DIR}/Glasser_HCP_v1.0.nii.gz
fi
 	
export LD_LIBRARY_PATH=/opt/freesurfer/MCRv84/runtime/glnxa64:/opt/freesurfer/MCRv84/bin/glnxa64:/opt/freesurfer/MCRv84/sys/os/glnxa64:/opt/freesurfer/MCRv84/sys/java/jre/glnxa64/jre/lib/amd64/native_threads:/opt/freesurfer/MCRv84/sys/java/jre/glnxa64/jre/lib/amd64/server:/opt/freesurfer/MCRv84/sys/java/jre/glnxa64/jre/lib/amd64


# Segmentation of hippocampal subfields
if [[ ${HIPPOCAMPUS} == "True" ]]; then
  echo -e "$CONTAINER  Starting segmentation of hippocampal subfields..."
  # OLD: recon-all -subjid "${SUBJECT_ID}" -hippocampal-subfields-T1
  # DEV:
  segmentHA_T1.sh "${SUBJECT_ID}"

  # if T2 input file
  if [[ -f "$T2_ANAT" ]]; then
    segmentHA_T2.sh "${SUBJECT_ID}" ${MRI_DIR}/T2.mgz 0 1
  fi

  # Longitudinal Processing of Hippocampus: NOT PERFORMING
  # segmentHA_T1_long.sh "${SUBJECT_ID}"
  # OLD: 
  # quantifyHippocampalSubfields.sh T1 "${MRI_DIR}"/HippocampalSubfields.txt
  # DEV:
  quantifyHAsubregions.sh hippoSf T1 "${MRI_DIR}"/HippocampalSubfields.txt ${SUBJECTS_DIR}
  quantifyHAsubregions.sh amygNuc T1 "${MRI_DIR}"/AmygdalaNuclei.txt ${SUBJECTS_DIR}
  # TODO: This is going to have to be parsed out.
  tr ' ' ',' <"${MRI_DIR}"/HippocampalSubfields.txt >${OUTPUT_DIR}/"${SUBJECT_ID}"_HippocampalSubfields.csv
  tr ' ' ',' <"${MRI_DIR}"/AmygdalaNuclei.txt >${OUTPUT_DIR}/"${SUBJECT_ID}"_AmygdalaNuclei.csv
fi

# Brainstem Substructures
if [[ ${BRAINSTEM} == "True" ]]; then
  echo -e "$CONTAINER  Starting segmentation of brainstem structures..."
  # OLD: recon-all -subjid "${SUBJECT_ID}" -brainstem-structures
  # DEV: 
  segmentBS.sh "${SUBJECT_ID}"
  quantifyBrainstemStructures.sh "${MRI_DIR}"/BrainstemStructures.txt
  tr ' ' ',' <"${MRI_DIR}"/BrainstemStructures.txt >${OUTPUT_DIR}/"${SUBJECT_ID}"_BrainstemStructures.csv
fi

# Thalamic Nuclei
if [[ ${THALAMUS} == "True" ]]; then
    echo -e "$CONTAINER  Starting segmentation of thalamic nuclei..."
    segmentThalamicNuclei.sh "${SUBJECT_ID}"
    # With nightly builds, "${MRI_DIR}"/ThalamicNuclei.${SUFFIX}.T1.volumes.txt
    # ${SUFFIX} is unstable
    ln -sfn "${MRI_DIR}"/ThalamicNuclei.*.T1.volumes.txt "${MRI_DIR}"/ThalamicNuclei.T1.volumes.txt
    tr ' ' ',' <"${MRI_DIR}"/ThalamicNuclei.T1.volumes.txt >${OUTPUT_DIR}/"${SUBJECT_ID}"_ThalamicNuclei.T1.volumes.csv

fi

export LD_LIBRARY_PATH=""

# Neuropythy retino-template algorithm
if [[ ${NEUROPYTHY} == "True" ]]; then
    echo -e "$CONTAINER  Starting Neuropythy retino-template ..."
    # Matlab installation interfers with neuropythy execution.
    SAVE_LD_LIBRARY_PATH=$LD_LIBRARY_PATH
    export LD_LIBRARY_PATH=
    
    python -m neuropythy atlas --verbose --volume-export "${SUBJECT_ID}"
    
    export LD_LIBRARY_PATH=$SAVE_LD_LIBRARY_PATH
fi
###############################################################################
# Optional registrations

if [[ $REGISTER_SURFACES == "True" ]]; then
  echo -e "$CONTAINER  Running surface registrations..."
  # Register hemispheres
  xhemireg --s "${SUBJECT_ID}"

  # Register the left hemisphere to fsaverage_sym
  surfreg --s "${SUBJECT_ID}" --t fsaverage_sym --lh

  # Register the inverted right hemisphere to fsaverage_sym
  surfreg --s "${SUBJECT_ID}" --t fsaverage_sym --lh --xhemi
fi


###############################################################################
# Convert the output surface and volume files
if [[ $CONVERT_SURFACES == "True" ]]; then

  # Convert selected surfaces in subject/surf to obj in output
  SURF_DIR=${SUBJECTS_DIR}/"${SUBJECT_ID}"/surf

  surfaces='lh.pial
            rh.pial
            lh.white
            rh.white
            rh.inflated
            lh.inflated'

  echo -e "$CONTAINER  Converting surfaces to object (.obj) files..."
  for i in $surfaces; do
      mris_convert "${SURF_DIR}"/$i "${SURF_DIR}"/$i.asc
      ${FLYWHEEL_BASE}/srf2obj "${SURF_DIR}"/$i.asc > ${OUTPUT_DIR}/$i.obj
  done

fi

# Convert select volumes in subject/mri to nifti:
if [[ $CONVERT_VOLUMES == "True" ]]; then

  MRI_DIR=${SUBJECTS_DIR}/"${SUBJECT_ID}"/mri
  mri_mgz_files='aparc+aseg.mgz
                 aparc.a2009s+aseg.mgz
                 brainmask.mgz
                 lh.ribbon.mgz
                 rh.ribbon.mgz
                 ribbon.mgz
                 aseg.mgz
                 orig.mgz
                 T1.mgz'

  if [[ ${HIPPOCAMPUS} == "True" ]]; then
    # Create a symbolic link to the development version of this output specified
    # by ${SUFFIX} in 
    # rh.hippoSfLabels-T1.${SUFFIX}.FSvoxelSpace.mgz"

    ln -sfn `ls "${MRI_DIR}"/lh.hippoAmygLabels-T1.*.FSvoxelSpace.mgz | egrep 'T1.v[0-9]+.FSvox'` "${MRI_DIR}"/lh.hippoAmygLabels-T1.FSvoxelSpace.mgz
    ln -sfn `ls "${MRI_DIR}"/rh.hippoAmygLabels-T1.*.FSvoxelSpace.mgz | egrep 'T1.v[0-9]+.FSvox'` "${MRI_DIR}"/rh.hippoAmygLabels-T1.FSvoxelSpace.mgz
    mri_mgz_files="$mri_mgz_files 
                   lh.hippoAmygLabels-T1.FSvoxelSpace.mgz
                   rh.hippoAmygLabels-T1.FSvoxelSpace.mgz"
  fi

  if [[ ${BRAINSTEM} == "True" ]]; then
    # Create a symbolic link to the development version of this output specified
    # by ${SUFFIX} in 
    # brainstemSsLabels.${SUFFIX}.FSvoxelSpace.mgz
    ln -sfn "${MRI_DIR}"/brainstemSsLabels.*.FSvoxelSpace.mgz "${MRI_DIR}"/brainstemSsLabels.FSvoxelSpace.mgz
    mri_mgz_files="$mri_mgz_files brainstemSsLabels.FSvoxelSpace.mgz"
  fi

  if [[ ${THALAMUS} == "True" ]]; then
    # Create a symbolic link to the development version of this output specified
    # by ${SUFFIX} in 
    # ThalamicNuclei.${SUFFIX}.T1.FSvoxelSpace.mgz
    ln -sfn "${MRI_DIR}"/ThalamicNuclei.*.T1.FSvoxelSpace.mgz "${MRI_DIR}"/ThalamicNuclei.T1.FSvoxelSpace.mgz
    mri_mgz_files="$mri_mgz_files ThalamicNuclei.T1.FSvoxelSpace.mgz"
  fi

  if [[ ${NEUROPYTHY} == "True" ]]; then
    mri_mgz_files="$mri_mgz_files 
                   wang15_mplbl.mgz
                   benson14_varea.mgz
                   benson14_eccen.mgz
                   benson14_sigma.mgz
                   benson14_angle.mgz"
  fi

  echo -e "$CONTAINER  Converting volumes to NIfTI files..."
  for i in $mri_mgz_files; do
    mri_convert -i "${MRI_DIR}"/$i -o ${OUTPUT_DIR}/`basename $i .mgz`.nii.gz
    mri_convert -i "${MRI_DIR}"/$i -o ${FS_DIR}/`basename $i .mgz`.nii.gz
  done

fi

##############################################################################
# Write ROIs separately into individual files
cp ${OUTPUT_DIR}/aparc+aseg.nii.gz   ${FS_DIR}/aparc+aseg.nii.gz

# Cerebellum
if [[ ${CEREBELLUM} == "True" ]]; then
	cp ${OUTPUT_DIR}/buckner2011_cerebellum.nii.gz ${FS_DIR}/buckner2011_cerebellum.nii.gz 
	${FLYWHEEL_BASE}/separateROIs.py -cb ${FS_DIR}/buckner2011_cerebellum.nii.gz 
fi

# Thalamic Nuclei
if [[ ${THALAMUS} == "True" ]]; then
	# separate nuclei from the ThalamicNuclei.T1.FSvoxelSpace.nii.gz
	# separate ROIs
	cp ${OUTPUT_DIR}/ThalamicNuclei.T1.FSvoxelSpace.nii.gz ${FS_DIR}/ThalamicNuclei.T1.FSvoxelSpace.nii.gz
	${FLYWHEEL_BASE}/separateROIs.py -ThN ${FS_DIR}/ThalamicNuclei.T1.FSvoxelSpace.nii.gz \
									 -ThLUT ${TEMPLATES}/FreesurferColorLUT_THALAMUS.txt 
	
fi

# HCP Atlas 
if [[ ${HCP} == "True" ]]; then
	# separate ROIs
	cp ${OUTPUT_DIR}/Glasser_HCP_v1.0.nii.gz ${FS_DIR}/Glasser_HCP_v1.0.nii.gz
	${FLYWHEEL_BASE}/separateROIs.py -hcp ${FS_DIR}/Glasser_HCP_v1.0.nii.gz \
									 -hcpLUT ${TEMPLATES}/LUT_HCP.txt 
	
fi


if [[ ${NEUROPYTHY} == "True" ]]; then
	cp ${OUTPUT_DIR}/benson14_varea.nii.gz  ${FS_DIR}/benson14_varea.nii.gz
	${FLYWHEEL_BASE}/separateROIs.py -benV ${FS_DIR}/benson14_varea.nii.gz

fi

if [[ ${APARC2009} == "True" ]]; then
	cp ${OUTPUT_DIR}/aparc.a2009s+aseg.nii.gz	${FS_DIR}/aparc.a2009s+aseg.nii.gz	
	${FLYWHEEL_BASE}/separateROIs.py -aparc2009 ${FS_DIR}/aparc.a2009s+aseg.nii.gz	
fi

###############################################################################
# Write aseg stats to a table

if [[ $ASEG_CSV == "True" ]]; then
  echo -e "$CONTAINER  Exporting stats files csv..."
  asegstats2table -s "${SUBJECT_ID}" \
      --delimiter comma \
      --tablefile="${OUTPUT_DIR}/${SUBJECT_ID}_aseg_stats_vol_mm3.csv"

  # Parse the aparc files and write to table
  hemi="lh rh"
  parc="aparc.a2009s aparc"
  for h in $hemi; do
      for p in $parc; do
        aparcstats2table -s "${SUBJECT_ID}" \
          --hemi=$h \
          --delimiter=comma \
          --parc=$p \
          --tablefile="${OUTPUT_DIR}/${SUBJECT_ID}_${h}_${p}_stats_area_mm2.csv"
      done
  done

    if [[ ${THALAMUS} == "True" ]]; then
        for h in $hemi; do
            # Create a symbolic link to the development version of this output specified
            # by ${SUFFIX} in 
            # thalamic-nuclei.${h}.${SUFFIX}.T1.stats
            ln -sfn ${SUBJECTS_DIR}/${SUBJECT_ID}/stats/thalamic-nuclei.${h}.*.T1.stats ${SUBJECTS_DIR}/${SUBJECT_ID}/stats/thalamic-nuclei.${h}.T1.stats
            asegstats2table -s "${SUBJECT_ID}" \
              --delimiter=comma \
              --statsfile=thalamic-nuclei.${h}.T1.stats \
              --tablefile="${OUTPUT_DIR}/${SUBJECT_ID}_thalamic-nuclei.${h}.T1.csv"
        done
    fi
fi


###############################################################################
# Compress Recon-all output directory
echo -e "$CONTAINER  Compressing final outputs..."

# Set file permissions prior to compression
chmod -R 777 ${WORK_DIR}
cd /
zip -r /${OUTPUT_DIR}/${GEAR}_"${SUBJECT_ID}"`date +"_D%m-%d-%yT%H-%M"`.zip "${SUBJECT_ID}"

# Now compress the FS_DIR that will be input to the rtp_pipeline
cd ${OUTPUT_DIR}

zip -r fs.zip fs


###############################################################################
# FINISH

# Get a list of the files in the output directory
outputs=$(find $OUTPUT_DIR/* -maxdepth 0 -type f -name "*.zip")

# If outputs exist, generate metadata, and exit
if [[ -z $outputs ]]; then
  echo "$CONTAINER  GEAR FAILED... Exiting(1)"
  exit 1
else
  # Set permissions for outputs (prevent root only r/w)
  chmod -R 777 $OUTPUT_DIR
  echo -e "$CONTAINER  Done!"
  exit 0
fi
